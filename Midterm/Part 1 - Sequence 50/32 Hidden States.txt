D:\Anaconda\python.exe "D:/Piradon Liengtiraphan Midterm/Midterm.py"
First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?

All:
Resolved. resolved.

First Citizen:
First, you
reading text file
vocabulary size: 65
Characters: (' ', 'e', 't', 'o', 'a', 'h', 's', 'r', 'n', 'i', '\n', 'l', 'd', 'u', 'm', 'y', ',', 'w', 'f', 'c', 'g', 'I', 'b', 'p', ':', '.', 'A', 'v', 'k', 'T', "'", 'E', 'O', 'N', 'R', 'S', 'L', 'C', ';', 'W', 'U', 'H', 'M', 'B', '?', 'G', '!', 'D', '-', 'F', 'Y', 'P', 'K', 'V', 'j', 'q', 'x', 'z', 'J', 'Q', 'Z', 'X', '3', '&', '$')
vocab number of 'F': 49
Character sequences (first batch): [[49  9  7 ...,  1  4  7]
 [19  4 14 ..., 14  9 20]
 [ 8 20 10 ...,  8 10 18]
 ..., 
 [21  2  0 ...,  0 21  0]
 [ 9  7  7 ...,  0  2  3]
 [ 3  7  0 ...,  5  9 23]]
[[49  9  7 ...,  1  4  7]
 [19  4 14 ..., 14  9 20]
 [ 8 20 10 ...,  8 10 18]
 ..., 
 [21  2  0 ...,  0 21  0]
 [ 9  7  7 ...,  0  2  3]
 [ 3  7  0 ...,  5  9 23]]
(60, 50)
[[ 9  7  6 ...,  4  7  0]
 [ 4 14 22 ...,  9 20  5]
 [20 10 29 ..., 10 18  4]
 ..., 
 [ 2  0  6 ..., 21  0  6]
 [ 7  7  4 ...,  2  3  0]
 [ 7  0 33 ...,  9 23  0]]
32
Tensor("Placeholder:0", shape=(60, 50), dtype=int32)
Tensor("Placeholder_1:0", shape=(60, 50), dtype=int32)
2017-10-18 20:11:56.307083: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-10-18 20:11:56.307897: W C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-10-18 20:11:56.594940: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:955] Found device 0 with properties: 
name: Quadro K2200
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:03:00.0
Total memory: 4.00GiB
Free memory: 3.35GiB
2017-10-18 20:11:56.595337: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:976] DMA: 0 
2017-10-18 20:11:56.595517: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:986] 0:   Y 
2017-10-18 20:11:56.596383: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K2200, pci bus id: 0000:03:00.0)
(60, 50, 32)
[[ 0.02761425 -0.09899041  0.20781378 ...,  0.11544155  0.03532751
   0.17740567]
 [ 0.21491112  0.0668685  -0.03432621 ..., -0.04440379  0.21236782
  -0.04245406]
 [ 0.09659584 -0.02256259 -0.11434278 ...,  0.0827754  -0.17961666
   0.02946283]
 ..., 
 [ 0.07791503  0.16400523  0.11830966 ..., -0.22785598 -0.10447872
  -0.22935654]
 [ 0.04746361  0.20265178 -0.17698067 ..., -0.0601943  -0.19425337
   0.1591336 ]
 [ 0.09659584 -0.02256259 -0.11434278 ...,  0.0827754  -0.17961666
   0.02946283]]
(<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_98:0' shape=(60, 32) dtype=float32>, <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_99:0' shape=(60, 32) dtype=float32>)
[<tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_1:0' shape=(60, 32) dtype=float32>, <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_3:0' shape=(60, 32) dtype=float32>, <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_5:0' shape=(60, 32) dtype=float32>, <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_7:0' shape=(60, 32) dtype=float32>, <tf.Tensor 'rnnlm_1/rnnlm/multi_rnn_cell/cell_0/cell_0/basic_rnn_cell/Tanh_9:0' shape=(60, 32) dtype=float32>]
Tensor("Reshape:0", shape=(3000, 32), dtype=float32)
Tensor("add:0", shape=(3000, 65), dtype=float32)
Tensor("Softmax:0", shape=(3000, 65), dtype=float32)
[<tf.Variable 'rnnlm/softmax_w:0' shape=(32, 65) dtype=float32_ref>, <tf.Variable 'rnnlm/softmax_b:0' shape=(65,) dtype=float32_ref>, <tf.Variable 'rnnlm/embedding:0' shape=(65, 32) dtype=float32_ref>, <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/kernel:0' shape=(64, 32) dtype=float32_ref>, <tf.Variable 'rnnlm/multi_rnn_cell/cell_0/basic_rnn_cell/bias:0' shape=(32,) dtype=float32_ref>]
2017-10-18 20:12:59.491023: I C:\tf_jenkins\home\workspace\rel-win\M\windows-gpu\PY\36\tensorflow\core\common_runtime\gpu\gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Quadro K2200, pci bus id: 0000:03:00.0)
370/46375 (epoch 0), train_loss = 2.255, time/batch = 0.031
>> sample mode:
The he lem-wese hou'd jqrecgersulis on is houdexturs h
----------------------------------
741/46375 (epoch 1), train_loss = 2.111, time/batch = 0.031
>> sample mode:
The my mure yow:
And avy bross lesgay,': and'd, wier;

----------------------------------
1112/46375 (epoch 2), train_loss = 2.044, time/batch = 0.016
>> sample mode:
The swere seesiws in come fain's are nocjomy apt
betti
----------------------------------
1483/46375 (epoch 3), train_loss = 2.003, time/batch = 0.000
>> sample mode:
The thother, ary you ford, have reanss we kist no hups
----------------------------------
1854/46375 (epoch 4), train_loss = 1.976, time/batch = 0.000
>> sample mode:
The hath foch he yeariour,
Noths I would eis go baing 
----------------------------------
2225/46375 (epoch 5), train_loss = 1.954, time/batch = 0.016
>> sample mode:
The obedope; boundael wellow' on drink a's tose youst,
----------------------------------
2596/46375 (epoch 6), train_loss = 1.935, time/batch = 0.016
>> sample mode:
The ansher are to waater be sertel a cound, fitich Ma 
----------------------------------
2967/46375 (epoch 7), train_loss = 1.919, time/batch = 0.016
>> sample mode:
The your be is loumed.

CLAUBASTE:
Hake
Madit be,
Arne
----------------------------------
3338/46375 (epoch 8), train_loss = 1.907, time/batch = 0.016
>> sample mode:
The mong? the sots be exen bland, as ints not seived I
----------------------------------
3709/46375 (epoch 9), train_loss = 1.897, time/batch = 0.016
>> sample mode:
The ty and he an thee be vat my greatert:
Suber my me;
----------------------------------
4080/46375 (epoch 10), train_loss = 1.891, time/batch = 0.016
>> sample mode:
The and
no, now from: antterdd waclaunt
Eno lort: till
----------------------------------
4451/46375 (epoch 11), train_loss = 1.885, time/batch = 0.016
>> sample mode:
The it
Ro-cor's of as you? I'll such,
undfiths agaly i
----------------------------------
4822/46375 (epoch 12), train_loss = 1.880, time/batch = 0.016
>> sample mode:
The to lifetwrad; 'cwaft I prany fricgiot?

HEPNE:
II'
----------------------------------
5193/46375 (epoch 13), train_loss = 1.876, time/batch = 0.016
>> sample mode:
The she thill feorunt promp not theut alate pelf limar
----------------------------------
5564/46375 (epoch 14), train_loss = 1.872, time/batch = 0.016
>> sample mode:
The pothy of worldse
Pofor?

Say, A
That I pean to sir
----------------------------------
5935/46375 (epoch 15), train_loss = 1.869, time/batch = 0.000
>> sample mode:
The ow iwed.

GLOUCESTER: the mext a ghou you Mustent 
----------------------------------
6306/46375 (epoch 16), train_loss = 1.866, time/batch = 0.011
>> sample mode:
The fitten,
At
Take his wor,
Tit mades;
Of Ghour Rufke
----------------------------------
6677/46375 (epoch 17), train_loss = 1.864, time/batch = 0.016
>> sample mode:
The scaugot not is you:--ame find, bblion me alk
noo
T
----------------------------------
7048/46375 (epoch 18), train_loss = 1.862, time/batch = 0.016
>> sample mode:
The So rot, I sertige!

CORIOLANUS:
Nhas offe you so c
----------------------------------
7419/46375 (epoch 19), train_loss = 1.860, time/batch = 0.016
>> sample mode:
The the but hath foul roudh by lose it I pensel of enc
----------------------------------
7790/46375 (epoch 20), train_loss = 1.858, time/batch = 0.016
>> sample mode:
The it Gwitand, some to ars me take
For!

COMINIUS:
Wh
----------------------------------
8161/46375 (epoch 21), train_loss = 1.856, time/batch = 0.016
>> sample mode:
The sayen:
Your, thorent
Wangaim!
You lise, God.

ANIO
----------------------------------
8532/46375 (epoch 22), train_loss = 1.854, time/batch = 0.000
>> sample mode:
The bofjor her sernus, and now come no but to ant in't
----------------------------------
8903/46375 (epoch 23), train_loss = 1.853, time/batch = 0.000
>> sample mode:
The wall a geals and this: ofpeathin othermis, be the

----------------------------------
9274/46375 (epoch 24), train_loss = 1.851, time/batch = 0.000
>> sample mode:
The your hath
His now, uncerictive, my lord I tome, wo
----------------------------------
9645/46375 (epoch 25), train_loss = 1.849, time/batch = 0.016
>> sample mode:
The ingers:
Itcy ge! and Jumt me shall I wats, mast th
----------------------------------
10016/46375 (epoch 26), train_loss = 1.848, time/batch = 0.016
>> sample mode:
The yatcered, ness and gaury: Anden kermed, fall theer
----------------------------------
10387/46375 (epoch 27), train_loss = 1.847, time/batch = 0.016
>> sample mode:
The Stray?

GRUSIOH:
I will,
Go have thoubee: of benee
----------------------------------
10758/46375 (epoch 28), train_loss = 1.845, time/batch = 0.016
>> sample mode:
The has bean's sud nid, will of xoo what to mice choll
----------------------------------
11129/46375 (epoch 29), train_loss = 1.844, time/batch = 0.000
>> sample mode:
The he with thou herkune wich misectenced terdedound t
----------------------------------
11500/46375 (epoch 30), train_loss = 1.843, time/batch = 0.000
>> sample mode:
The with,
Router and or say, lord, deible agnekuter: a
----------------------------------
11871/46375 (epoch 31), train_loss = 1.842, time/batch = 0.016
>> sample mode:
The a moungeeded his preem a a,
cruckle, wesced! and h
----------------------------------
12242/46375 (epoch 32), train_loss = 1.842, time/batch = 0.016
>> sample mode:
The al frughteradly, Busbre.

FLORTAUS:
Why, wice.

GL
----------------------------------
12613/46375 (epoch 33), train_loss = 1.841, time/batch = 0.000
>> sample mode:
The shrelerdudente,
From atd she by mear bunted frie l
----------------------------------
12984/46375 (epoch 34), train_loss = 1.840, time/batch = 0.016
>> sample mode:
The everonave; I hath kime as what of that rempir.

HE
----------------------------------
13355/46375 (epoch 35), train_loss = 1.839, time/batch = 0.031
>> sample mode:
The I'll Dovery as
Fit are spe bure pun Enour to fap:

----------------------------------
13726/46375 (epoch 36), train_loss = 1.839, time/batch = 0.016
>> sample mode:
The father Bo
Wise eaming'etes trunk misons
A divement
----------------------------------
14097/46375 (epoch 37), train_loss = 1.838, time/batch = 0.016
>> sample mode:
The is countidamen.
Then, wher what sole here ip'it my
----------------------------------
14468/46375 (epoch 38), train_loss = 1.838, time/batch = 0.000
>> sample mode:
The quonte
can
Yes stlir:
Hereft crigh, base thee.

CA
----------------------------------
14839/46375 (epoch 39), train_loss = 1.837, time/batch = 0.016
>> sample mode:
The bettest: no sufssized tho get for to protcouge, so
----------------------------------
15210/46375 (epoch 40), train_loss = 1.836, time/batch = 0.007
>> sample mode:
The ewtrer'dd now earrand draves, the rite, their! whe
----------------------------------
15581/46375 (epoch 41), train_loss = 1.836, time/batch = 0.008
>> sample mode:
The like is what thange couds old natirs man the mouta
----------------------------------
15952/46375 (epoch 42), train_loss = 1.835, time/batch = 0.000
>> sample mode:
The tell that one mereng or Pet as one and have hesssl
----------------------------------
16323/46375 (epoch 43), train_loss = 1.835, time/batch = 0.016
>> sample mode:
The done; forster for tison-fathers of wor
Soman, my d
----------------------------------
16694/46375 (epoch 44), train_loss = 1.834, time/batch = 0.011
>> sample mode:
The tried them wis is kind, whider:
For my proviouch i
----------------------------------
17065/46375 (epoch 45), train_loss = 1.834, time/batch = 0.000
>> sample mode:
The thou all ruve to het is as a'lstelfs:
Inas we plea
----------------------------------
17436/46375 (epoch 46), train_loss = 1.833, time/batch = 0.016
>> sample mode:
The as hate, I preen so the not their to desposcempor 
----------------------------------
17807/46375 (epoch 47), train_loss = 1.833, time/batch = 0.016
>> sample mode:
The and you solanes sull jedther, fool. I'ld, inforfol
----------------------------------
18178/46375 (epoch 48), train_loss = 1.832, time/batch = 0.000
>> sample mode:
The hustry; I dow ibless any play, but I nother mides-
----------------------------------
18549/46375 (epoch 49), train_loss = 1.832, time/batch = 0.000
>> sample mode:
The my Give old densivers, my londer, driefw condar:
B
----------------------------------
18920/46375 (epoch 50), train_loss = 1.831, time/batch = 0.016
>> sample mode:
The foriourd the of brgon,
Astom gonder, is ran
What a
----------------------------------
19291/46375 (epoch 51), train_loss = 1.831, time/batch = 0.016
>> sample mode:
The than.

SIELLO:
And than--

ERILLA:
'Tyir.

BUTHEMT
----------------------------------
19662/46375 (epoch 52), train_loss = 1.831, time/batch = 0.000
>> sample mode:
The pon jain'd of the gair the lie for agless me arvat
----------------------------------
20033/46375 (epoch 53), train_loss = 1.830, time/batch = 0.000
>> sample mode:
The hous ruquatllatinoss fereant do we'll?

YORK:
I co
----------------------------------
20404/46375 (epoch 54), train_loss = 1.830, time/batch = 0.031
>> sample mode:
The for, fafy ho, what yow we shall, where.

LUCIO:
So
----------------------------------
20775/46375 (epoch 55), train_loss = 1.829, time/batch = 0.016
>> sample mode:
The noy that you her in I deceses
We the gate think me
----------------------------------
21146/46375 (epoch 56), train_loss = 1.829, time/batch = 0.000
>> sample mode:
The sleadrenton; that you yis fay shuitter toads, my s
----------------------------------
21517/46375 (epoch 57), train_loss = 1.829, time/batch = 0.016
>> sample mode:
The morpost, no grips:
I
Theisiwar to to buty, her sta
----------------------------------
21888/46375 (epoch 58), train_loss = 1.828, time/batch = 0.000
>> sample mode:
The anmars,
The of that! Hath sir that scompute is I h
----------------------------------
22259/46375 (epoch 59), train_loss = 1.828, time/batch = 0.016
>> sample mode:
The man, all honoury,
I'ld the wert trains.

MENENIUS:
----------------------------------
22630/46375 (epoch 60), train_loss = 1.828, time/batch = 0.000
>> sample mode:
The sich so granting.

BROCANUSEREP:
This subned one w
----------------------------------
23001/46375 (epoch 61), train_loss = 1.827, time/batch = 0.016
>> sample mode:
The best hake uswnignmant,
And must you sorny sayn him
----------------------------------
23372/46375 (epoch 62), train_loss = 1.827, time/batch = 0.016
>> sample mode:
The come;
Beelfol:
I deep oor; the manced this rid the
----------------------------------
23743/46375 (epoch 63), train_loss = 1.827, time/batch = 0.000
>> sample mode:
The dear, then batt me here here we this a frinst ibui
----------------------------------
24114/46375 (epoch 64), train_loss = 1.826, time/batch = 0.016
>> sample mode:
The toore our have heel a some
ane
For thy begeromand.
----------------------------------
24485/46375 (epoch 65), train_loss = 1.826, time/batch = 0.016
>> sample mode:
The ford,
I hates.

KING RATELB;
and honikn,
warl for 
----------------------------------
24856/46375 (epoch 66), train_loss = 1.826, time/batch = 0.000
>> sample mode:
The I mound. Twering wome
Un; and-mustreve the king ar
----------------------------------
25227/46375 (epoch 67), train_loss = 1.826, time/batch = 0.016
>> sample mode:
The our muphele let the, 'dorrems: forms, Stown, in us
----------------------------------
25598/46375 (epoch 68), train_loss = 1.825, time/batch = 0.000
>> sample mode:
The smy paster sirs is must he what late,
Or to oect'd
----------------------------------
25969/46375 (epoch 69), train_loss = 1.825, time/batch = 0.031
>> sample mode:
The offesh if game,
And as iffieds of we put to the go
----------------------------------
26340/46375 (epoch 70), train_loss = 1.825, time/batch = 0.016
>> sample mode:
The destrunt,
And dear, men dinge; where, some now for
----------------------------------
26711/46375 (epoch 71), train_loss = 1.825, time/batch = 0.011
>> sample mode:
The wno go.

PETREBEY.
While;
Whenam, thy dacuo, and h
----------------------------------
27082/46375 (epoch 72), train_loss = 1.824, time/batch = 0.000
>> sample mode:
The thornacle,
A Londer, sir!
A! mides
Are a sectime h
----------------------------------
27453/46375 (epoch 73), train_loss = 1.824, time/batch = 0.016
>> sample mode:
The will it, an's dreavence, the Enscompare:
No!
Thine
----------------------------------
27824/46375 (epoch 74), train_loss = 1.824, time/batch = 0.000
>> sample mode:
The he be graust his Bucless thore,:
Syallard for acci
----------------------------------
28195/46375 (epoch 75), train_loss = 1.824, time/batch = 0.000
>> sample mode:
The meat, prift I pensty be bind good sempher, as yet:
----------------------------------
28566/46375 (epoch 76), train_loss = 1.824, time/batch = 0.016
>> sample mode:
The I would all you I llows
For renir, Rabought ot mus
----------------------------------
28937/46375 (epoch 77), train_loss = 1.823, time/batch = 0.016
>> sample mode:
The if Sentio?
Gorth
No'th, that we him canse'
Yem, wh
----------------------------------
29308/46375 (epoch 78), train_loss = 1.823, time/batch = 0.016
>> sample mode:
The it Shaince-hagush denclaer the dive, hear you?

CA
----------------------------------
29679/46375 (epoch 79), train_loss = 1.823, time/batch = 0.016
>> sample mode:
The his hack, our suto ottion the weept arm he but, of
----------------------------------
30050/46375 (epoch 80), train_loss = 1.823, time/batch = 0.016
>> sample mode:
The peir he hast in in theingost-nied, slead tell thy 
----------------------------------
30421/46375 (epoch 81), train_loss = 1.823, time/batch = 0.031
>> sample mode:
The con; ond jet yours and enfin coment,
He puck
En if
----------------------------------
30792/46375 (epoch 82), train_loss = 1.823, time/batch = 0.016
>> sample mode:
The send, ther must a eaming,
And,
To bow of' arvied L
----------------------------------
31163/46375 (epoch 83), train_loss = 1.823, time/batch = 0.031
>> sample mode:
The sound air, arlasraize have bear with well he hef h
----------------------------------
31534/46375 (epoch 84), train_loss = 1.822, time/batch = 0.031
>> sample mode:
The sead again noadises'd.

Fidl.

BUCKINGHAMI PETERO:
----------------------------------
31905/46375 (epoch 85), train_loss = 1.822, time/batch = 0.016
>> sample mode:
The the make hated inford is.

CRICILA:
To exgly a cun
----------------------------------
32276/46375 (epoch 86), train_loss = 1.822, time/batch = 0.000
>> sample mode:
The extracime! Whor be your brood noo he heldit an Ben
----------------------------------
32647/46375 (epoch 87), train_loss = 1.822, time/batch = 0.016
>> sample mode:
The you?
If I cond:
He make your hount,
And thy day, t
----------------------------------
33018/46375 (epoch 88), train_loss = 1.822, time/batch = 0.000
>> sample mode:
The of un what eny atly word, I slomemistar,
mading bi
----------------------------------
33389/46375 (epoch 89), train_loss = 1.822, time/batch = 0.000
>> sample mode:
The theme beeit of's duke soned of lord gentor, feling
----------------------------------
33760/46375 (epoch 90), train_loss = 1.822, time/batch = 0.016
>> sample mode:
The stray'd that, oquow, beyss,
He gorbee.

SLACKING,

----------------------------------
34131/46375 (epoch 91), train_loss = 1.822, time/batch = 0.016
>> sample mode:
The hou--HNCDADky to wath or, awour good camt merbut s
----------------------------------
34502/46375 (epoch 92), train_loss = 1.822, time/batch = 0.016
>> sample mode:
The the hold a vetesay; I will so a toud've. Hongersti
----------------------------------
34873/46375 (epoch 93), train_loss = 1.822, time/batch = 0.000
>> sample mode:
The ruverion so deith stath, look?

CLONTAS:
Be can's 
----------------------------------
35244/46375 (epoch 94), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The rest.

HAMIOLK:
I prictpe mannio, buar enviors wer
----------------------------------
35615/46375 (epoch 95), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The strainy
he our do deal be in milizen,
So priassort
----------------------------------
35986/46375 (epoch 96), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The are but,
It we rnue.

Them, it thu murth like lesh
----------------------------------
36357/46375 (epoch 97), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The nay know's fay'd I call Sayes. angry see these cay
----------------------------------
36728/46375 (epoch 98), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The gentorsher on of his gosth wither he gone he
Then 
----------------------------------
37099/46375 (epoch 99), train_loss = 1.821, time/batch = 0.031
>> sample mode:
The wiress jesten, but
Thore own che alemer,
Whitan se
----------------------------------
37470/46375 (epoch 100), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The the mort, day arbsest gorth, wiedes must entwe
and
----------------------------------
37841/46375 (epoch 101), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The sheep the wifaw willast is shap ongurtend herlant'
----------------------------------
38212/46375 (epoch 102), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The lireds take golf enruteraccained and was heel with
----------------------------------
38583/46375 (epoch 103), train_loss = 1.821, time/batch = 0.000
>> sample mode:
The s'dow blow! What ettire thy gates art that again n
----------------------------------
38954/46375 (epoch 104), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The cate strant
And them law made,
Ro storsirench, ard
----------------------------------
39325/46375 (epoch 105), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The hank not dispoud,
And you for shath withisalm, Hee
----------------------------------
39696/46375 (epoch 106), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The how be refeth?

ANCERIZELLA:
No say,
prisugnling w
----------------------------------
40067/46375 (epoch 107), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The word thy many late.

QUENIK:
Like thee with the we
----------------------------------
40438/46375 (epoch 108), train_loss = 1.821, time/batch = 0.016
>> sample mode:
The senerdouse Sey, to let his partere wrovic-wonder t
----------------------------------
40809/46375 (epoch 109), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The ichascest the poccharles at as dra turtch Ruche, f
----------------------------------
41180/46375 (epoch 110), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The this mers owy meat, I murt.

RATHAS:
Where a meref
----------------------------------
41551/46375 (epoch 111), train_loss = 1.820, time/batch = 0.000
>> sample mode:
The doth'll be god hem; when--

AUTOLYRA:
Me strourss 
----------------------------------
41922/46375 (epoch 112), train_loss = 1.820, time/batch = 0.018
>> sample mode:
The leisbly saw treak made Say.

JULIET:
And time life
----------------------------------
42293/46375 (epoch 113), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The a mutallland, diend Made
me shall prevet that not 
----------------------------------
42664/46375 (epoch 114), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The is is the croth have in, befal as my dradon spach'
----------------------------------
43035/46375 (epoch 115), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The that's out's the couconess
That hanks alostek that
----------------------------------
43406/46375 (epoch 116), train_loss = 1.820, time/batch = 0.000
>> sample mode:
The forbarites suster and unaistinent gry depso 'Tyild
----------------------------------
43777/46375 (epoch 117), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The Kistein
Thou some to Hastosposs-put, Most, Yor, an
----------------------------------
44148/46375 (epoch 118), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The my amore.

GSCBALUFDINIA:
Why chall Engurchided I 
----------------------------------
44519/46375 (epoch 119), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The chick art abamit: by to beit rever ward they hadt?
----------------------------------
44890/46375 (epoch 120), train_loss = 1.820, time/batch = 0.000
>> sample mode:
The you herst your peep thee of tilghe geispeln, dear-
----------------------------------
45261/46375 (epoch 121), train_loss = 1.820, time/batch = 0.031
>> sample mode:
The thershord-fartion pan.

ClO:
O would un scille:
Yo
----------------------------------
45632/46375 (epoch 122), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The upbeally,
Were
Here-karderss to may them I toivout
----------------------------------
46003/46375 (epoch 123), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The neicp'llant than thangilly you the landers till of
----------------------------------
46374/46375 (epoch 124), train_loss = 1.820, time/batch = 0.016
>> sample mode:
The will'st dooths, that
She cordom, merrinds-fatie.
M
----------------------------------

Process finished with exit code 0
